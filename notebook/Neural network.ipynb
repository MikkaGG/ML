{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b24aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076a1099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 119 entries, 0 to 118\n",
      "dtypes: float64(119)\n",
      "memory usage: 929.8 KB\n"
     ]
    }
   ],
   "source": [
    "data_classifier = pd.read_csv(\"D:\\ML\\data\\weather_data.csv\", delimiter=',')\n",
    "data_regressor = pd.read_csv(\"D:\\ML\\data\\data.csv\", delimiter=',')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(data_classifier)\n",
    "\n",
    "data_classifier = scaler.transform(data_classifier)\n",
    "data_classifier = pd.DataFrame(data_classifier)\n",
    "\n",
    "data_classifier = data_classifier[:1000]\n",
    "\n",
    "balance = len(data_classifier.loc[data_classifier[16]==0])//len(data_classifier.loc[data_classifier[16]==1])\n",
    "\n",
    "data_sample = data_classifier.loc[data_classifier[16]==1]\n",
    "data_sample = data_sample.loc[data_sample.index.repeat(balance)]\n",
    "data_n = pd.concat([data_classifier.loc[data_classifier[16]==0], data_sample]).sample(frac=1)\n",
    "\n",
    "\n",
    "y_regression = data_regressor[\"quality\"]\n",
    "X_regression = data_regressor.drop([\"quality\"], axis=1)\n",
    "y_classification = data_n[16]\n",
    "X_classification = data_n.drop([16], axis=1)\n",
    "\n",
    "data_classifier.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78cda13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5320 entries, 0 to 5319\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         5320 non-null   float64\n",
      " 1   volatile acidity      5320 non-null   float64\n",
      " 2   citric acid           5320 non-null   float64\n",
      " 3   residual sugar        5320 non-null   float64\n",
      " 4   chlorides             5320 non-null   float64\n",
      " 5   free sulfur dioxide   5320 non-null   float64\n",
      " 6   total sulfur dioxide  5320 non-null   float64\n",
      " 7   density               5320 non-null   float64\n",
      " 8   pH                    5320 non-null   float64\n",
      " 9   sulphates             5320 non-null   float64\n",
      " 10  alcohol               5320 non-null   float64\n",
      " 11  quality               5320 non-null   float64\n",
      " 12  kind_red              5320 non-null   float64\n",
      " 13  kind_white            5320 non-null   float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 582.0 KB\n"
     ]
    }
   ],
   "source": [
    "data_regressor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e5aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(X_regression,\n",
    "                                                                                                y_regression,\n",
    "                                                                                                test_size=0.2)\n",
    "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
    "                                                                                                                y_classification,\n",
    "                                                                                                                stratify=y_classification,\n",
    "                                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0a53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(13,)),\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86cd0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b398dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89568f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "133/133 [==============================] - 2s 3ms/step - loss: 15.7599\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.5697\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.1163\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.9202\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.6184\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.4579\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3459\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2923\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2266\n",
      "Epoch 10/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2253\n",
      "Epoch 11/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1846\n",
      "Epoch 12/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0639\n",
      "Epoch 13/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0467\n",
      "Epoch 14/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0182\n",
      "Epoch 15/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9811\n",
      "Epoch 16/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9179\n",
      "Epoch 17/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 18/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8741\n",
      "Epoch 19/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8418\n",
      "Epoch 20/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8547\n",
      "Epoch 21/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8759\n",
      "Epoch 22/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7898\n",
      "Epoch 23/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7842\n",
      "Epoch 24/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7943\n",
      "Epoch 25/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7517\n",
      "Epoch 26/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7864\n",
      "Epoch 27/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7371\n",
      "Epoch 28/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6924\n",
      "Epoch 29/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6876\n",
      "Epoch 30/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6840\n",
      "Epoch 31/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6622\n",
      "Epoch 32/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6642\n",
      "Epoch 33/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6777\n",
      "Epoch 34/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6768\n",
      "Epoch 35/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6545\n",
      "Epoch 36/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6299\n",
      "Epoch 37/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6352\n",
      "Epoch 38/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6115\n",
      "Epoch 39/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5904\n",
      "Epoch 40/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5996\n",
      "Epoch 41/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6015\n",
      "Epoch 42/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5918\n",
      "Epoch 43/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5802\n",
      "Epoch 44/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6032\n",
      "Epoch 45/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5754\n",
      "Epoch 46/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5916\n",
      "Epoch 47/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5803\n",
      "Epoch 48/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 49/50\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5938\n",
      "Epoch 50/50\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.6105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190dc1845e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_regression_train, y_regression_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9affa233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.610996034808625\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.5980170786809164\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.11285227356612619\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.7733156397493305\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_absolute_percentage_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(sqrt(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a12eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190dc4dd1e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(118,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e088d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9598435 ],\n",
       "       [0.99116   ],\n",
       "       [0.9394521 ],\n",
       "       [0.98863643],\n",
       "       [0.94279975]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc68c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.88      0.90      1621\n",
      "         1.0       0.88      0.93      0.90      1519\n",
      "\n",
      "    accuracy                           0.90      3140\n",
      "   macro avg       0.90      0.90      0.90      3140\n",
      "weighted avg       0.91      0.90      0.90      3140\n",
      "\n",
      "[[1419  202]\n",
      " [ 101 1418]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7256a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 1 / y_classification_train[y_classification_train==0].shape[0]\n",
    "w1 = 1 / y_classification_train[y_classification_train==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d0a6331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90      1621\n",
      "         1.0       0.86      0.96      0.91      1519\n",
      "\n",
      "    accuracy                           0.90      3140\n",
      "   macro avg       0.91      0.91      0.90      3140\n",
      "weighted avg       0.91      0.90      0.90      3140\n",
      "\n",
      "[[1383  238]\n",
      " [  63 1456]]\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(118,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})\n",
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f43247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190ea6bc6d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(118,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
    "model_classification_2.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad7ff379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03064739, 0.9693526 ],\n",
       "       [0.03000836, 0.9699916 ],\n",
       "       [0.16266857, 0.8373314 ],\n",
       "       [0.00269466, 0.9973053 ],\n",
       "       [0.21390928, 0.7860907 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a604dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(X_classification_test, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc030b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90      1621\n",
      "         1.0       0.86      0.96      0.90      1519\n",
      "\n",
      "    accuracy                           0.90      3140\n",
      "   macro avg       0.91      0.90      0.90      3140\n",
      "weighted avg       0.91      0.90      0.90      3140\n",
      "\n",
      "[[1381  240]\n",
      " [  67 1452]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e31c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_regression.save('../models/RegressionModel')\n",
    "model_classification_1.save('../models/ClassificationModel1')\n",
    "model_classification_2.save('../models/ClassificationModel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64eb2d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression_restored = tf.keras.models.load_model('../models/RegressionModel')\n",
    "model_regression_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4530e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.610996034808625\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.5980170786809164\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.11285227356612619\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "0.7733156397493305\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_absolute_percentage_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(sqrt(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb4fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5397923875432526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, neurons, activation):\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, layers, epoch, learning_rate):\n",
    "        self.layers = layers\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def sigmoid(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def dsigmoid(x):\n",
    "        return Perceptron.sigmoid(x) * (1 - Perceptron.sigmoid(x))\n",
    "    \n",
    "    def relu(x):\n",
    "         return np.where(x > 0, x, 0)\n",
    "    \n",
    "    def tahn(x):\n",
    "        return (np.exp(2*x) - 1)/(np.exp(2*x) + 1) \n",
    "    \n",
    "    def drelu(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "    \n",
    "    def dtahn(x):\n",
    "        return 4/((np.exp(x) + np.exp(-x)) ** 2) \n",
    "    \n",
    "    def func(x):\n",
    "        return np.where(x > 0.5, 1, 0)\n",
    "    \n",
    "    def Weight(self, X, Y):\n",
    "        W = []\n",
    "        b = []\n",
    "        w = np.array([np.random.uniform(-1, 1, (len(X.iloc[0]), self.layers[0].neurons))])\n",
    "        w = w.reshape(len(X.iloc[0]), self.layers[0].neurons)\n",
    "        b_i = np.array([np.random.uniform(-1, 1, (len(X.iloc[0]), self.layers[0].neurons))])\n",
    "        b_i = b_i.reshape(len(X.iloc[0]), self.layers[0].neurons)\n",
    "        W.append(w)\n",
    "        b.append(b_i)\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            w = np.array([np.random.uniform(-1, 1, (self.layers[i].neurons, self.layers[i+1].neurons))])\n",
    "            w = w.reshape(self.layers[i].neurons, self.layers[i+1].neurons)\n",
    "            W.append(w)\n",
    "            b_i = np.array([np.random.uniform(-1, 1, (self.layers[i].neurons, self.layers[i+1].neurons))])\n",
    "            b_i = w.reshape(self.layers[i].neurons, self.layers[i+1].neurons)\n",
    "            b.append(b_i)\n",
    "        return W, b\n",
    "    \n",
    "    def first_way(self, W, b, X, y):\n",
    "        p = []\n",
    "        out = np.array([])\n",
    "        for sample in range(len(X)):\n",
    "            W, b = Perceptron.Weight(self, X, y)\n",
    "            p_i = []\n",
    "            for i in range(len(self.layers)):\n",
    "                if i == 0:\n",
    "                    preAct = np.dot(X.iloc[sample, :], W[i] + b[i])\n",
    "                    if self.layers[i].activation == 'sigmoid':\n",
    "                        postAct = Perceptron.sigmoid(preAct)\n",
    "                    elif self.layers[i].activation == 'relu':\n",
    "                        postAct = Perceptron.relu(preAct)\n",
    "                    else:\n",
    "                        postAct = Perceptron.tahn(preAct)\n",
    "                    p_i.append(postAct)\n",
    "                elif i == len(self.layers) - 1:\n",
    "                    preAct = np.dot(postAct, W[i]+ b[i])\n",
    "                    if self.layers[i].activation == 'sigmoid':\n",
    "                        postAct = Perceptron.sigmoid(preAct)\n",
    "                    elif self.layers[i].activation == 'relu':\n",
    "                        postAct = Perceptron.relu(preAct)\n",
    "                    else:\n",
    "                        postAct = Perceptron.tahn(preAct)\n",
    "                    out = np.append(out, postAct)\n",
    "                else:\n",
    "                    preAct = np.dot(postAct, W[i]+ b[i])\n",
    "                    if self.layers[i].activation == 'sigmoid':\n",
    "                        postAct = Perceptron.sigmoid(preAct)\n",
    "                    elif self.layers[i].activation == 'relu':\n",
    "                        postAct = Perceptron.relu(preAct)\n",
    "                    else:\n",
    "                        postAct = Perceptron.tahn(preAct)\n",
    "                    p_i.append(postAct)\n",
    "            p.append(p_i)\n",
    "        return out\n",
    "    \n",
    "    def fit(self, W, b, X, y, out):\n",
    "        Q = 0\n",
    "        w_q = W\n",
    "        b_q = b\n",
    "        \n",
    "        for ep in range(self.epoch):\n",
    "            for sample in range(len(X)):\n",
    "                Q += ((np.linalg.norm(out[sample] - y[sample])**2) / 2)\n",
    "            Q /= len(X)\n",
    "\n",
    "            for i in range(len(W)):\n",
    "                for j in range(len(W[i])):\n",
    "                    for k in range(len(W[i][j])):\n",
    "                        if self.layers[i].activation == 'sigmoid':\n",
    "                            error = Q * Perceptron.dsigmoid(W[i][j][k])\n",
    "                            error_ = Q * Perceptron.dsigmoid(b[i][j][k])\n",
    "                        elif self.layers[i].activation == 'relu':\n",
    "                            error = Q * Perceptron.drelu(W[i][j][k])\n",
    "                            error_ = Q * Perceptron.drelu(b[i][j][k])\n",
    "                        else:\n",
    "                            error = Q * Perceptron.dtahn(W[i][j][k])\n",
    "                            error_ = Q * Perceptron.dtahn(b[i][j][k])\n",
    "                        w_q[i][j][k] = error * W[i][j][k]\n",
    "                        b_q[i][j][k] = error_ * b[i][j][k]\n",
    "\n",
    "            for i in range(len(W)):\n",
    "                for j in range(len(W[i])):\n",
    "                    for k in range(len(W[i][j])):\n",
    "                        W[i][j][k] = W[i][j][k] - self.learning_rate * w_q[i][j][k]\n",
    "                        b[i][j][k] = b[i][j][k] - self.learning_rate * b_q[i][j][k]\n",
    "        return W, b\n",
    "                \n",
    "    def predict(self, X, W, b):\n",
    "        y_pred = []\n",
    "        y_predicted = []\n",
    "\n",
    "        for sample in range(len(X)):\n",
    "            for i in range(len(self.layers)):\n",
    "                if i == 0:\n",
    "                    preAct = np.dot(X.iloc[sample, :], W[i] + b[i])\n",
    "                    if self.layers[i].activation == 'sigmoid':\n",
    "                        postAct = Perceptron.sigmoid(preAct)\n",
    "                    elif self.layers[i].activation == 'relu':\n",
    "                        postAct = Perceptron.relu(preAct)\n",
    "                    else:\n",
    "                        postAct = Perceptron.tahn(preAct)\n",
    "                elif i != len(self.layers) - 1:\n",
    "                    preAct = np.dot(postAct, W[i] + b[i])\n",
    "                    if self.layers[i].activation == 'sigmoid':\n",
    "                        postAct = Perceptron.sigmoid(preAct)\n",
    "                    elif self.layers[i].activation == 'relu':\n",
    "                        postAct = Perceptron.relu(preAct)\n",
    "                    else:\n",
    "                        postAct = Perceptron.tahn(preAct)\n",
    "                else:\n",
    "                    preAct = np.dot(postAct, W[i] + b[i])\n",
    "                    y_predicted.append(Perceptron.func(preAct))\n",
    "        for i in range(len(y_predicted)):\n",
    "            if (y_predicted[i] == 1):\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return y_pred\n",
    "            \n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "        \n",
    "cat = Perceptron(layers = [Layer(neurons=3, activation='relu'),\n",
    "                           Layer(neurons=2, activation='tahn'), Layer(neurons=1, activation='sigmoid')],\n",
    "                 epoch=100, learning_rate=0.01)\n",
    "W, b = cat.Weight(X_classification_train, y_classification_train)\n",
    "out = cat.first_way(W, b, X_classification_train, y_classification_train)\n",
    "y_classification_train_np = np.array([y_classification_train])\n",
    "y_classification_train_np = y_classification_train_np.ravel()\n",
    "W, b = cat.fit(W, b, X_classification_train, y_classification_train_np, out)\n",
    "y_pred = cat.predict(X_classification_test, W, b)\n",
    "print(cat.accuracy(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998cec00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
